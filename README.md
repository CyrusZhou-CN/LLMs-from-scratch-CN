
<p align="center">
<h1 align="center"> <img src="./imgs/icon/ai.png" width="30" />《从零构建大模型》</h1>
</p>
<p align="center">
    <a href="https://img.shields.io/badge/version-v0.1.0-blue">
      <img alt="version" src="https://img.shields.io/badge/version-v0.1.0-blue?color=FF8000?color=009922" />
    </a>
  <a >
       <img alt="Status-building" src="https://img.shields.io/badge/Status-building-blue" />
    </a>
  <a >
       <img alt="PRs-Welcome" src="https://img.shields.io/badge/PRs-Welcome-red" />
    </a>
    <a href="https://github.com/MLNLP-World/LLMs-from-scratch-CN/stargazers">
       <img alt="stars" src="https://img.shields.io/github/stars/MLNLP-World/LLMs-from-scratch-CN" />
    </a>
    <a href="https://github.com/MLNLP-World/LLMs-from-scratch-CN/network/members">
       <img alt="FORK" src="https://img.shields.io/github/forks/MLNLP-World/LLMs-from-scratch-CN?color=FF8000" />
    </a>
    <a href="https://github.com/MLNLP-World/LLMs-from-scratch-CN/issues">
      <img alt="Issues" src="https://img.shields.io/github/issues/MLNLP-World/LLMs-from-scratch-CN?color=0088ff"/>
    </a>
    <br />
</p>

<div align="center">
<p align="center">
  <a href="#项目动机">项目动机</a>/
  <a href="#课程简介">课程简介</a>/
  <a href="#课程资源">课程资源</a>/
  <a href="#原书Readme">原书Readme</a>/
  <a href="#贡献者">贡献者</a>
</p>
</div>

---

<h2 id="项目动机">
  <img src="./imgs/icon/motivation.png" width="25" /> 项目动机
</h2>


原项目与地址:[《LLMs-from-scratch》](https://github.com/rasbt/LLMs-from-scratch.git)

本项目是对GitHub项目[《LLMs-from-scratch》](https://github.com/rasbt/LLMs-from-scratch.git)内容的中文翻译，包括详细的markdown 笔记和相关的jupyter 代码。翻译过程中，我们尽可能保持原意的准确性，同时对部分内容进行了语序和表达的优化，以更贴合中文学习者的阅读习惯。需要特别说明的是，原作者为该项目的主要贡献者，本汉化版本仅作为学习辅助资料，不对原内容进行修改或延伸。

由于个人能力有限，翻译中可能存在不完善之处，欢迎提出宝贵意见并多多包涵 希望通过这一翻译项目，更多中文学习者能够从中受益，也希望为国内社区的 LLM 学习和研究贡献一份力量。

>本项目的特色：
>**jupyter代码**均有详细中文注释，帮助大家更快上手实践。
>**诸多的附加材料**可以拓展知识

本项目所用徽章来自互联网，如侵犯了您的图片版权请联系我们删除，谢谢。

<h2 id="课程简介">
  <img src="./imgs/icon/intro.png" width="25" /> 课程简介
</h2>

提到大语言模型（LLMs），我们可能会将其视为独立于传统机器学习的领域，但实际上，LLMs 是机器学习的一个重要分支。在深度学习尚未广泛应用之前，机器学习在许多领域（如语音识别、自然语言处理、计算机视觉等）的作用相对有限，因为这些领域往往需要大量的专业知识来应对复杂的现实问题。然而，近几年深度学习的快速发展彻底改变了这一状况，使 LLMs 成为推动人工智能技术革命的关键力量。

原项目与地址:[《LLMs-from-scratch》](https://github.com/rasbt/LLMs-from-scratch.git)
[https://github.com/rasbt/LLMs-from-scratch.git](https://github.com/rasbt/LLMs-from-scratch.git)

在 [《LLMs-from-scratch》](https://github.com/rasbt/LLMs-from-scratch.git)项目中，不仅关注 LLMs 的基础构建，如 Transformer 架构、序列建模 等，还深入探索了 GPT、BERT 等深度学习模型 的底层实现。项目中的每一部分均配备详细的代码实现和学习资源，帮助学习者从零开始构建 LLMs，全面掌握其核心技术。

<h2 id="课程资源">
  <img src="./imgs/icon/resource.png" width="25" /> 课程资源
</h2>

- 英文原版地址：[原版地址](https://github.com/rasbt/LLMs-from-scratch.git)
- 教材网址：[原版教材](amzn.to/4fqvn0D)
- 汉化地址：[https://github.com/MLNLP-World/LLMs-from-scratch-CN.git](https://github.com/MLNLP-World/LLMs-from-scratch-CN.git)

此外，本门课程还有相应的代码实现。**每章都有相应的jupyter记事本，提供模型的完整python代码**，所有的资源都可在网上免费获取。



<h2 id="原书Readme">
  <img src="./imgs/icon/notes.png" width="25" /> 原书Readme
</h2>

# 从零构建大模型

这个仓库包含了开发、预训练和微调一个类似GPT的LLM（大语言模型）的代码，是《从零构建大模型》这本书的官方代码仓库，书籍链接：[从零构建大模型](https://amzn.to/4fqvn0D)。

<br>
<br>

<a href="https://amzn.to/4fqvn0D"><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/cover.jpg?123" width="250px"></a>

<br>

在《*从零构建大模型*》这本书中，您将逐步了解大语言模型（LLMs）如何从内到外工作，自己动手编写代码，逐步构建一个LLM。在这本书中，我将通过清晰的文字、图示和示例，带您完成构建自己LLM的每一个阶段。

本书描述的训练和开发自己的小型功能性模型的方法，旨在教育用途，类似于用于创建大规模基础模型（如ChatGPT背后的模型）的方法。此外，本书还包括加载更大预训练模型权重进行微调的代码。

- 官方[源代码仓库链接](https://github.com/rasbt/LLMs-from-scratch)
- 汉化版本[汉化仓库链接](https://github.com/GoatCsu/LLMs-from-scratch-CN-CSU)
- [出版商网站上的书籍链接](http://mng.bz/orYv)
- [Amazon.com上的书籍页面链接](https://www.amazon.com/gp/product/1633437167)
- ISBN 9781633437166

<a href="http://mng.bz/orYv#reviews"><img src="https://sebastianraschka.com//images/LLMs-from-scratch-images/other/reviews.png" width="220px"></a>

<br>

要下载此仓库的副本，请点击[下载ZIP](https://github.com/rasbt/LLMs-from-scratch/archive/refs/heads/main.zip)按钮，或者在终端中执行以下命令：

```bash
git clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git
```

要下载此仓库汉化版本，请点击[下载ZIP](https://github.com/MLNLP-World/LLMs-from-scratch-CN.git)按钮，或者在终端中执行以下命令：

```bash
git clone --depth 1 https://github.com/MLNLP-World/LLMs-from-scratch-CN.git
```

<br>

(如果您是从Manning网站下载的代码包，请访问官方代码仓库 [https://github.com/rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) 获取最新的更新
或者汉化版本[https://github.com/MLNLP-World/LLMs-from-scratch-CN.git](https://github.com/MLNLP-World/LLMs-from-scratch-CN.git))

<br>

# 目录

请注意，本文档是一个Markdown (`.md`) 文件。如果您是从Manning网站下载的代码包并在本地查看它，建议使用Markdown编辑器或预览器进行正确查看。如果您尚未安装Markdown编辑器，[MarkText](https://www.marktext.cc) 是一个不错的免费选项。

您也可以通过浏览器访问GitHub上的[代码仓库](https://github.com/rasbt/LLMs-from-scratch)，或者[汉化版](https://github.com/MLNLP-World/LLMs-from-scratch-CN.git)浏览器会自动渲染Markdown。

<br>
<!--  -->

> [!TIP]
> 如果您需要安装Python和Python包以及设置代码环境的指导，建议阅读[README.md](setup/README.md) 文件，该文件位于[setup](setup)目录中。

<br>

| **章节标题**                                       | **主要代码（快速访问）**                                                                                                                                               | **所有代码及补充内容**         | **翻译者** | **校对者** |
|---------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------|------------|------------|
| [安装建议](setup)                                 | -                                                                                                                                                                     | -                              | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> |  <a href="https://github.com/BRZ911">  <img src="./imgs/profile/yongheng.jpg"  width="80" /></a> |
| **第1章：理解大型语言模型**                        | 无代码                                                                                                                                                                | -                              | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> |  <a href="https://github.com/BRZ911">  <img src="./imgs/profile/yongheng.jpg"  width="80" /></a> |
| **第2章：处理文本数据**                            | - [ch02.ipynb](ch02/01_main-chapter-code/ch02.ipynb) <br/>- [dataloader.ipynb](ch02/01_main-chapter-code/dataloader.ipynb)（总结） <br/>- [exercise-solutions.ipynb](ch02/01_main-chapter-code/exercise-solutions.ipynb) | [ch02](./ch02)                | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> |  <a href="https://github.com/BRZ911">  <img src="./imgs/profile/yongheng.jpg"  width="80" /></a> |
| **第3章：编码注意力机制**                          | - [ch03.ipynb](ch03/01_main-chapter-code/ch03.ipynb) <br/>- [multihead-attention.ipynb](ch03/01_main-chapter-code/multihead-attention.ipynb)（总结） <br/>- [exercise-solutions.ipynb](ch03/01_main-chapter-code/exercise-solutions.ipynb) | [ch03](./ch03)                | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> |  <a href="https://github.com/BRZ911">  <img src="./imgs/profile/yongheng.jpg"  width="80" /></a> |
| **第4章：从零开始实现 GPT 模型**                   | - [ch04.ipynb](ch04/01_main-chapter-code/ch04.ipynb) <br/>- [gpt.py](ch04/01_main-chapter-code/gpt.py)（总结） <br/>- [exercise-solutions.ipynb](ch04/01_main-chapter-code/exercise-solutions.ipynb) | [ch04](./ch04)                | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> |  <a href="https://github.com/BRZ911">  <img src="./imgs/profile/yongheng.jpg"  width="80" /></a> |
| **第5章：在无标注数据上进行预训练**                | - [ch05.ipynb](ch05/01_main-chapter-code/ch05.ipynb) <br/>- [gpt_train.py](ch05/01_main-chapter-code/gpt_train.py)（总结） <br/>- [gpt_generate.py](ch05/01_main-chapter-code/gpt_generate.py)（总结） <br/>- [exercise-solutions.ipynb](ch05/01_main-chapter-code/exercise-solutions.ipynb) | [ch05](./ch05)                | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> |  <a href="https://github.com/WPENGxs">  <img src="./imgs/profile/wpengxs.jpg"  width="80" /></a> |
| **第6章：进行文本分类的微调**                      | - [ch06.ipynb](ch06/01_main-chapter-code/ch06.ipynb) <br/>- [gpt_class_finetune.py](ch06/01_main-chapter-code/gpt_class_finetune.py) <br/>- [exercise-solutions.ipynb](ch06/01_main-chapter-code/exercise-solutions.ipynb) | [ch06](./ch06)                | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> | <a href="https://github.com/WPENGxs">  <img src="./imgs/profile/wpengxs.jpg"  width="80" /></a> |
| **第7章：进行遵循指令的微调**                      | - [ch07.ipynb](ch07/01_main-chapter-code/ch07.ipynb) <br/>- [gpt_instruction_finetuning.py](ch07/01_main-chapter-code/gpt_instruction_finetuning.py)（总结） <br/>- [ollama_evaluate.py](ch07/01_main-chapter-code/ollama_evaluate.py)（总结） <br/>- [exercise-solutions.ipynb](ch07/01_main-chapter-code/exercise-solutions.ipynb) | [ch07](./ch07)                | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> |  <a href="https://github.com/WPENGxs">  <img src="./imgs/profile/wpengxs.jpg"  width="80" /></a> |
| **附录 A：PyTorch 简介**                           | - [code-part1.ipynb](appendix-A/01_main-chapter-code/code-part1.ipynb) <br/>- [code-part2.ipynb](appendix-A/01_main-chapter-code/code-part2.ipynb) <br/>- [DDP-script.py](appendix-A/01_main-chapter-code/DDP-script.py) <br/>- [exercise-solutions.ipynb](appendix-A/01_main-chapter-code/exercise-solutions.ipynb) | [appendix-A](./appendix-A)    | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> |  <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/chunlin.png"  width="80" /></a> |
| **附录 B：参考文献与进一步阅读**                  | 无代码                                                                                                                                                                | -                              |  |   |
| **附录 C：习题解答**                               | 无代码                                                                                                                                                                | -                              |    |   |
| **附录 D：在训练循环中加入附加功能**               | - [appendix-D.ipynb](appendix-D/01_main-chapter-code/appendix-D.ipynb)                                                                                                | [appendix-D](./appendix-D)    | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/chunlin.png"  width="80" /></a> |
| **附录 E：使用 LoRA 进行参数高效微调**            | - [appendix-E.ipynb](appendix-E/01_main-chapter-code/appendix-E.ipynb)                                                                                                | [appendix-E](./appendix-E)    | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/chunlin.png"  width="80" /></a> |

<br>
&nbsp;

下图是本书内容的总结性思维导图。
<img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/mental-model.jpg" width="650px">

<br>

<br>

&nbsp;
## 额外材料

| **章节**                                          | **附加资料**                                                                                                                                                                            | **翻译者**    | **校对者**                                                                                                                                       |
|--------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------|
| **设置**                                          | - [Python 设置提示](setup/01_optional-python-setup-preferences) <br> - [安装本书中使用的 Python 包和库](setup/02_installing-python-libraries) <br> - [Docker 环境设置指南](setup/03_optional-docker-environment) | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a>      |  <a href="https://github.com/BRZ911">  <img src="./imgs/profile/yongheng.jpg"  width="80" /></a> |
| **第二章：处理文本数据**                           | - [从零开始实现字节对编码（BPE）分词器](ch02/05_bpe-from-scratch/bpe-from-scratch.ipynb) <br> - [比较不同字节对编码（BPE）实现](ch02/02_bonus_bytepair-encoder) <br> - [理解嵌入层和线性层的区别](ch02/03_bonus_embedding-vs-matmul) <br> - [用简单数字直观理解数据加载器](ch02/04_bonus_dataloader-intuition) | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a>                                               |  <a href="https://github.com/BRZ911">  <img src="./imgs/profile/yongheng.jpg"  width="80" /></a> |
| **第三章：编码注意力机制**                         | - [比较高效的多头注意力实现](ch03/02_bonus_efficient-multihead-attention/mha-implementations.ipynb) <br> - [理解 PyTorch 缓冲区](ch03/03_understanding-buffers/understanding-buffers.ipynb) | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a>                                               |  <a href="https://github.com/BRZ911">  <img src="./imgs/profile/yongheng.jpg"  width="80" /></a> |
| **第四章：从零开始实现 GPT 模型**                  | - [FLOPS 性能分析](ch04/02_performance-analysis/flops-analysis.ipynb)                                                                                                                   | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a>                                               |  <a href="https://github.com/WPENGxs">  <img src="./imgs/profile/wpengxs.jpg"  width="80" /></a> |
| **第五章：在未标注数据上进行预训练**              | - [使用 Transformers 从 Hugging Face 模型库加载替代权重](ch05/02_alternative_weight_loading/weight-loading-hf-transformers.ipynb) <br> - [在古腾堡计划数据集上预训练 GPT](ch05/03_bonus_pretraining_on_gutenberg) <br> - [为训练循环添加附加功能](ch05/04_learning_rate_schedulers) <br> - [优化预训练的超参数](ch05/05_bonus_hparam_tuning) <br> - [构建与预训练 LLM 交互的用户界面](ch05/06_user_interface) <br> - [将 GPT 转换为 Llama](ch05/07_gpt_to_llama) <br> - [从零开始构建 Llama 3.2](ch05/07_gpt_to_llama/standalone-llama32.ipynb) <br> - [内存高效的模型权重加载](ch05/08_memory_efficient_weight_loading/memory-efficient-state-dict.ipynb) <br> - [扩展 Tiktoken BPE 分词器，添加新 Token](ch05/09_extending-tokenizers/extend-tiktoken.ipynb) | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a>                                               |  <a href="https://github.com/WPENGxs">  <img src="./imgs/profile/wpengxs.jpg"  width="80" /></a> |
| **第六章：用于分类的微调**                         | - [微调不同层并使用更大模型的额外实验](ch06/02_bonus_additional-experiments) <br> - [在 50k IMDB 电影评论数据集上微调不同模型](ch06/03_bonus_imdb-classification) <br> - [构建与 GPT 基于垃圾邮件分类器交互的用户界面](ch06/04_user_interface) | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a>                                               | <a href="https://github.com/lul0308">  <img src="./imgs/profile/chunlin.png"  width="80" /></a>  |
| **第七章：微调以跟随指令**                         | - [查找近重复项和创建被动语态条目的数据集工具](ch07/02_dataset-utilities) <br> - [使用 OpenAI API 和 Ollama 评估指令响应](ch07/03_model-evaluation) <br> - [为指令微调生成数据集](ch07/05_dataset-generation/llama3-ollama.ipynb) <br> - [改进指令微调数据集](ch07/05_dataset-generation/reflection-gpt4.ipynb) <br> - [使用 Llama 3.1 70B 和 Ollama 生成偏好数据集](ch07/04_preference-tuning-with-dpo/create-preference-data-ollama.ipynb) <br> - [用于 LLM 对齐的直接偏好优化（DPO）](ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb) <br> - [构建与指令微调的 GPT 模型交互的用户界面](ch07/06_user_interface) | <a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a>                                               |  <a href="https://github.com/lul0308">  <img src="./imgs/profile/chunlin.png"  width="80" /></a> |

<br>

&nbsp;

## 硬件要求

本书主要章节中的代码设计为能够在常规笔记本电脑上运行，并且不会占用过长时间，因此不需要专门的硬件。这种方式确保了广泛的读者群体能够参与其中。此外，如果有可用的 GPU，代码会自动使用它们。（更多建议请参考 [setup](https://github.com/MLNLP-World/LLMs-from-scratch-CN.git/blob/main/setup/README.md) 文档。）

&nbsp;


## 问题、反馈和贡献

欢迎各种形式的反馈，最好通过 [Manning 论坛](https://livebook.manning.com/forum?product=raschka&page=1) 或 [GitHub 讨论区](https://github.com/rasbt/LLMs-from-scratch/discussions) 分享。如果你有任何问题或只是想与他人讨论想法，也请随时在论坛中发布。

请注意，由于本存储库包含与印刷书籍相对应的代码，因此目前无法接受扩展主要章节代码内容的贡献，因为这可能会导致与实体书籍的内容不一致。保持一致性有助于确保每个人的顺畅体验。

&nbsp;
## 引用

如果你发现本书或代码对你的研究有帮助，请考虑引用它。

引用：

> Raschka, Sebastian. *Build A Large Language Model (From Scratch)*. Manning, 2024. ISBN: 978-1633437166.

BibTeX 条目：
```
@book{build-llms-from-scratch-book,
author       = {Sebastian Raschka},
title        = {Build A Large Language Model (From Scratch)},
publisher    = {Manning},
year         = {2024},
isbn         = {978-1633437166},
url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},
github       = {https://github.com/rasbt/LLMs-from-scratch}
}
```


<h2 id="贡献者">
  <img src="./imgs/icon/heart.png" width="25" /> 贡献者
</h2>

<a href="https://github.com/GoatCsu">  <img src="./imgs/profile/GoatCsu.png"  width="80" /></a> 
<a href="https://github.com/BRZ911">  <img src="./imgs/profile/yongheng.jpg"  width="80" /></a>
<a href="https://github.com/WPENGxs">  <img src="./imgs/profile/wpengxs.jpg"  width="80" /></a>
<a href="https://github.com/lul0308">  <img src="./imgs/profile/chunlin.png"  width="80" /></a>
<a href="https://github.com/llm-chaser">  <img src="./imgs/profile/llm-chaser.jpeg"  width="80" /></a>